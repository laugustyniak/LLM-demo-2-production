# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_llm_intro/00_intro_to_llms.ipynb.

# %% auto 0
__all__ = ['get_completion', 'get_completion_from_messages']

# %% ../nbs/00_llm_intro/00_intro_to_llms.ipynb 3
import openai
import os

from dotenv import load_dotenv, find_dotenv

# %% ../nbs/00_llm_intro/00_intro_to_llms.ipynb 6
def get_completion(prompt, model="gpt-3.5-turbo"):
    messages = [{"role": "user", "content": prompt}]
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=0, # this is the degree of randomness of the model's output
    )
    return response.choices[0].message["content"]

def get_completion_from_messages(messages, model="gpt-3.5-turbo", temperature=0):
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=temperature, # this is the degree of randomness of the model's output
    )
#     print(str(response.choices[0].message))
    return response.choices[0].message["content"]
