{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiPromptChain Router\n",
    "\n",
    "> How can we use router to choose the best prompt for a given task?\n",
    "\n",
    "- title-block-banner: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Load the API key and relevant Python libaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use google colab please install the following packages:\n",
    "\n",
    "```bash\n",
    "pip install \"langchain>=0.0.200\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    # openai_api_key=\"sk-<your key here>\"  # uncomment to use your own API key, othewise uses default .env key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_template = \"\"\"\n",
    "Summarize the following text delimited by triple backticks with 1 sentence.\n",
    "Paper:\n",
    "```{input}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_audience_summary_template = \"\"\"\n",
    "Generate general audience a title for research paper.\n",
    "Paper:\n",
    "```{input}```\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_template = \"\"\"\n",
    "Prepare a tweet thread with 3 tweets based on paper description.\n",
    "Paper:\n",
    "```{input}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_template = \"\"\"\n",
    "Prepare a longer linkedin post based on paper description. \n",
    "Paper:\n",
    "```{input}```\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"summary\", \n",
    "        \"description\": \"Good for academic summarizing research papers\",\n",
    "        \"prompt_template\": summary_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"general_title\", \n",
    "        \"description\": \"Good for general audience title of paper\", \n",
    "        \"prompt_template\": general_audience_summary_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"twitter\",\n",
    "        \"description\": \"Good for twitter thread\",\n",
    "        \"prompt_template\": twitter_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"linkedin\",\n",
    "        \"description\": \"Good for linkedin post\",\n",
    "        \"prompt_template\": linkedin_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "chain = MultiPromptChain.from_prompts(OpenAI(), prompt_infos, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "summary: {'input': 'This work presents the most extensive open massively multilingual corpus of datasets for training sentiment models. The corpus consists of 79 manually selected datasets from over 350 datasets reported in the scientific literature based on strict quality criteria. The corpus covers 27 languages representing 6 language families. Datasets can be queried using several linguistic and functional features. In addition, we present a multi-faceted sentiment classification benchmark summarizing hundreds of experiments conducted on different base models, training objectives, dataset collections, and fine-tuning strategies.'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "This paper presents an extensive open corpus of datasets and a multi-faceted sentiment classification benchmark for 27 languages from 6 language families.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "chain.run(\"\"\"\n",
    "generale academic summary for \n",
    "Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted Sentiment Classification Benchmark\n",
    "Łukasz Augustyniak, Szymon Woźniak, Marcin Gruza, Piotr Gramacki, Krzysztof Rajda, Mikołaj Morzy, Tomasz Kajdanowicz\n",
    "Despite impressive advancements in multilingual corpora collection and model training, developing large-scale deployments of multilingual models still presents a significant challenge. This is particularly true for language tasks that are culture-dependent. One such example is the area of multilingual sentiment analysis, where affective markers can be subtle and deeply ensconced in culture. This work presents the most extensive open massively multilingual corpus of datasets for training sentiment models. The corpus consists of 79 manually selected datasets from over 350 datasets reported in the scientific literature based on strict quality criteria. The corpus covers 27 languages representing 6 language families. Datasets can be queried using several linguistic and functional features. In addition, we present a multi-faceted sentiment classification benchmark summarizing hundreds of experiments conducted on different base models, training objectives, dataset collections, and fine-tuning strategies.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "twitter: {'input': 'Introducing the most extensive open massively multilingual corpus of datasets for training sentiment models. With 79 manually selected datasets from over 350 datasets reported in the scientific literature, the corpus covers 27 languages representing 6 language families. Learn more about our multi-faceted sentiment classification benchmark!'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n1. Introducing the most extensive open massively multilingual corpus of datasets for training sentiment models! 79 manually selected datasets from over 350 datasets reported in the scientific literature. Learn more about our multi-faceted sentiment classification benchmark. #SentimentAnalysis #DataScience #AI \\n\\n2. Covering 27 languages from 6 language families, our corpus provides a comprehensive resource for researchers working in sentiment analysis. Check out our benchmark and explore the potential of sentiment models! #SentimentAnalysis #DataScience #AI \\n\\n3. Ready to take your sentiment analysis models to the next level? Our multilingual corpus provides the resources you need. Download it now and take advantage of the best sentiment models available! #SentimentAnalysis #DataScience #AI'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "chain.run(\"\"\"\n",
    "I need it for twitter \n",
    "Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted Sentiment Classification Benchmark\n",
    "Łukasz Augustyniak, Szymon Woźniak, Marcin Gruza, Piotr Gramacki, Krzysztof Rajda, Mikołaj Morzy, Tomasz Kajdanowicz\n",
    "Despite impressive advancements in multilingual corpora collection and model training, developing large-scale deployments of multilingual models still presents a significant challenge. This is particularly true for language tasks that are culture-dependent. One such example is the area of multilingual sentiment analysis, where affective markers can be subtle and deeply ensconced in culture. This work presents the most extensive open massively multilingual corpus of datasets for training sentiment models. The corpus consists of 79 manually selected datasets from over 350 datasets reported in the scientific literature based on strict quality criteria. The corpus covers 27 languages representing 6 language families. Datasets can be queried using several linguistic and functional features. In addition, we present a multi-faceted sentiment classification benchmark summarizing hundreds of experiments conducted on different base models, training objectives, dataset collections, and fine-tuning strategies.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
