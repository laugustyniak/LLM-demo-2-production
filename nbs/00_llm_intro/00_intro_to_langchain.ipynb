{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guidelines for Prompting in Langachain\n",
    "\n",
    "> **Guidelines for Prompting in Langachain**.\n",
    "\n",
    "- title-block-banner: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Load the API key and relevant Python libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "chat = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "paper_info = \"\"\"\n",
    "Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted Sentiment Classification Benchmark\n",
    "ﾅ「kasz Augustyniak, Szymon Woﾅｺniak, Marcin Gruza, Piotr Gramacki, Krzysztof Rajda, MikoﾅＢj Morzy, Tomasz Kajdanowicz\n",
    "Despite impressive advancements in multilingual corpora collection and model training, developing large-scale deployments of multilingual models still presents a significant challenge. This is particularly true for language tasks that are culture-dependent. One such example is the area of multilingual sentiment analysis, where affective markers can be subtle and deeply ensconced in culture. This work presents the most extensive open massively multilingual corpus of datasets for training sentiment models. The corpus consists of 79 manually selected datasets from over 350 datasets reported in the scientific literature based on strict quality criteria. The corpus covers 27 languages representing 6 language families. Datasets can be queried using several linguistic and functional features. In addition, we present a multi-faceted sentiment classification benchmark summarizing hundreds of experiments conducted on different base models, training objectives, dataset collections, and fine-tuning strategies.\n",
    "\"\"\"\n",
    "\n",
    "template_string = \"\"\"\n",
    "Perform the following actions for a research paper text: \n",
    "1 - Summarize the following text delimited by triple backticks with 1 sentence.\n",
    "2 - Generate a title for this summary with emojis.\n",
    "3 - Prepare a tweet thread with 3 tweets based on summary.\n",
    "4 - Prepare a longer linkedin post based on paper abstract. \n",
    "\n",
    "Return a {format_output} with the following strcuture: summary, title, tweet, linkedin_post \n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['text', 'format_output'], output_parser=None, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_output', 'text'], output_parser=None, partial_variables={}, template='\\nPerform the following actions for a research paper text: \\n1 - Summarize the following text delimited by triple backticks with 1 sentence.\\n2 - Generate a title for this summary with emojis.\\n3 - Prepare a tweet thread with 3 tweets based on summary.\\n4 - Prepare a longer linkedin post based on paper abstract. \\n\\nReturn a {format_output} with the following strcuture: summary, title, tweet, linkedin_post \\n\\nText:\\n```{text}```\\n', template_format='f-string', validate_template=True), additional_kwargs={})])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_output', 'text'], output_parser=None, partial_variables={}, template='\\nPerform the following actions for a research paper text: \\n1 - Summarize the following text delimited by triple backticks with 1 sentence.\\n2 - Generate a title for this summary with emojis.\\n3 - Prepare a tweet thread with 3 tweets based on summary.\\n4 - Prepare a longer linkedin post based on paper abstract. \\n\\nReturn a {format_output} with the following strcuture: summary, title, tweet, linkedin_post \\n\\nText:\\n```{text}```\\n', template_format='f-string', validate_template=True), additional_kwargs={})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "prompt_template.messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['format_output', 'text']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "paper_messages = prompt_template.format_messages(\n",
    "    text=paper_info,\n",
    "    format_output='python dict'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='\\nPerform the following actions for a research paper text: \\n1 - Summarize the following text delimited by triple backticks with 1 sentence.\\n2 - Generate a title for this summary with emojis.\\n3 - Prepare a tweet thread with 3 tweets based on summary.\\n4 - Prepare a longer linkedin post based on paper abstract. \\n\\nReturn a python dict with the following strcuture: summary, title, tweet, linkedin_post \\n\\nText:\\n```\\nMassively Multilingual Corpus of Sentiment Datasets and Multi-faceted Sentiment Classification Benchmark\\nﾅ「kasz Augustyniak, Szymon Woﾅｺniak, Marcin Gruza, Piotr Gramacki, Krzysztof Rajda, MikoﾅＢj Morzy, Tomasz Kajdanowicz\\nDespite impressive advancements in multilingual corpora collection and model training, developing large-scale deployments of multilingual models still presents a significant challenge. This is particularly true for language tasks that are culture-dependent. One such example is the area of multilingual sentiment analysis, where affective markers can be subtle and deeply ensconced in culture. This work presents the most extensive open massively multilingual corpus of datasets for training sentiment models. The corpus consists of 79 manually selected datasets from over 350 datasets reported in the scientific literature based on strict quality criteria. The corpus covers 27 languages representing 6 language families. Datasets can be queried using several linguistic and functional features. In addition, we present a multi-faceted sentiment classification benchmark summarizing hundreds of experiments conducted on different base models, training objectives, dataset collections, and fine-tuning strategies.\\n```\\n', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "paper_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain.schema.HumanMessage'>\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(type(paper_messages))\n",
    "print(type(paper_messages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "paper_social_media_summary = chat(paper_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Summary: 沍昨沒 This paper presents a massively multilingual corpus of sentiment datasets consisting of 79 manually selected datasets from over 350 reported in scientific literature, covering 27 languages and a multi-faceted sentiment classification benchmark summarizing hundreds of experiments conducted on different models, objectives, collections, and strategies.\\n\\nTitle: 沍昨沒 Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted Sentiment Classification Benchmark\\n\\nTweet 1: 沍昨沒 This paper presents a massively multilingual corpus of sentiment datasets covering 27 languages and a multi-faceted sentiment classification benchmark summarizing hundreds of experiments conducted on different models, objectives, collections, and strategies. #sentimentanalysis #multilingual\\n\\nTweet 2: 沒 The corpus consists of 79 manually selected datasets from over 350 reported in scientific literature based on strict quality criteria and can be queried using several linguistic and functional features. #dataset #NLP\\n\\nTweet 3: 沍昨沒 The multi-faceted sentiment classification benchmark presented in this paper provides a comprehensive evaluation of different base models, training objectives, dataset collections, and fine-tuning strategies. #machinelearning #evaluation\\n\\nLinkedIn Post: \\nThis paper presents a massively multilingual corpus of sentiment datasets and a multi-faceted sentiment classification benchmark, providing a comprehensive resource for sentiment analysis research. The corpus consists of 79 manually selected datasets from over 350 reported in scientific literature based on strict quality criteria, covering 27 languages representing 6 language families. Datasets can be queried using several linguistic and functional features, making it a valuable resource for natural language processing research. The multi-faceted sentiment classification benchmark summarizes hundreds of experiments conducted on different base models, training objectives, dataset collections, and fine-tuning strategies, providing a comprehensive evaluation of sentiment analysis approaches. This work is a significant contribution to the development of large-scale deployments of multilingual sentiment models, which still presents a significant challenge due to the culture-dependent nature of language tasks. #sentimentanalysis #multilingual #NLP #machinelearning #research', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "paper_social_media_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Summary: 沍昨沒 This paper presents a massively multilingual corpus of sentiment datasets consisting of 79 manually selected datasets from over 350 reported in scientific literature, covering 27 languages and a multi-faceted sentiment classification benchmark summarizing hundreds of experiments conducted on different models, objectives, collections, and strategies.\\n\\nTitle: 沍昨沒 Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted Sentiment Classification Benchmark\\n\\nTweet 1: 沍昨沒 This paper presents a massively multilingual corpus of sentiment datasets covering 27 languages and a multi-faceted sentiment classification benchmark summarizing hundreds of experiments conducted on different models, objectives, collections, and strategies. #sentimentanalysis #multilingual\\n\\nTweet 2: 沒 The corpus consists of 79 manually selected datasets from over 350 reported in scientific literature based on strict quality criteria and can be queried using several linguistic and functional features. #dataset #NLP\\n\\nTweet 3: 沍昨沒 The multi-faceted sentiment classification benchmark presented in this paper provides a comprehensive evaluation of different base models, training objectives, dataset collections, and fine-tuning strategies. #machinelearning #evaluation\\n\\nLinkedIn Post: \\nThis paper presents a massively multilingual corpus of sentiment datasets and a multi-faceted sentiment classification benchmark, providing a comprehensive resource for sentiment analysis research. The corpus consists of 79 manually selected datasets from over 350 reported in scientific literature based on strict quality criteria, covering 27 languages representing 6 language families. Datasets can be queried using several linguistic and functional features, making it a valuable resource for natural language processing research. The multi-faceted sentiment classification benchmark summarizes hundreds of experiments conducted on different base models, training objectives, dataset collections, and fine-tuning strategies, providing a comprehensive evaluation of sentiment analysis approaches. This work is a significant contribution to the development of large-scale deployments of multilingual sentiment models, which still presents a significant challenge due to the culture-dependent nature of language tasks. #sentimentanalysis #multilingual #NLP #machinelearning #research'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "paper_social_media_summary.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"| Summary | Title | Tweet | LinkedIn Post |\\n| --- | --- | --- | --- |\\n| This paper presents a massively multilingual corpus of sentiment datasets consisting of 79 manually selected datasets from over 350 datasets reported in the scientific literature based on strict quality criteria, covering 27 languages representing 6 language families, and a multi-faceted sentiment classification benchmark summarizing hundreds of experiments conducted on different base models, training objectives, dataset collections, and fine-tuning strategies. | 沍昨沒嬉汨 A Massive Multilingual Sentiment Corpus and Classification Benchmark | 1/3: Check out this paper presenting a massively multilingual corpus of sentiment datasets and a multi-faceted sentiment classification benchmark! 沍昨沒嬉汨 #sentimentanalysis #multilingual #corpus #classificationbenchmark | This paper presents a massively multilingual corpus of sentiment datasets and a multi-faceted sentiment classification benchmark, which can be used to train sentiment models in various languages and evaluate their performance. The corpus consists of 79 manually selected datasets from over 350 datasets reported in the scientific literature based on strict quality criteria, covering 27 languages representing 6 language families. The benchmark summarizes hundreds of experiments conducted on different base models, training objectives, dataset collections, and fine-tuning strategies, providing a comprehensive evaluation of the state-of-the-art in multilingual sentiment analysis. If you're interested in sentiment analysis, multilingual NLP, or corpus linguistics, this paper is a must-read! 沍昨沒嬉汨 #sentimentanalysis #multilingual #corpus #classificationbenchmark #naturallanguageprocessing #corpuslinguistics |\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "chat(prompt_template.format_messages(\n",
    "    text=paper_info,\n",
    "    format_output='markdown table'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain: Memory\n",
    "\n",
    "### ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is ﾅ「kasz\n",
      "AI:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello ﾅ「kasz, it's nice to meet you! My name is AI. How can I assist you today?\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "conversation.predict(input=\"Hi, my name is ﾅ「kasz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is ﾅ「kasz\n",
      "AI: Hello ﾅ「kasz, it's nice to meet you! My name is AI. How can I assist you today?\n",
      "Human: What is the best joke ever?\n",
      "AI:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'That\\'s a subjective question, as humor is different for everyone. However, one of the most popular jokes of all time is \"Why did the chicken cross the road? To get to the other side!\"'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "conversation.predict(input=\"What is the best joke ever?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is ﾅ「kasz\n",
      "AI: Hello ﾅ「kasz, it's nice to meet you! My name is AI. How can I assist you today?\n",
      "Human: What is the best joke ever?\n",
      "AI: That's a subjective question, as humor is different for everyone. However, one of the most popular jokes of all time is \"Why did the chicken cross the road? To get to the other side!\"\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is ﾅ「kasz, as you mentioned earlier.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is ﾅ「kasz\n",
      "AI: Hello ﾅ「kasz, it's nice to meet you! My name is AI. How can I assist you today?\n",
      "Human: What is the best joke ever?\n",
      "AI: That's a subjective question, as humor is different for everyone. However, one of the most popular jokes of all time is \"Why did the chicken cross the road? To get to the other side!\"\n",
      "Human: What is my name?\n",
      "AI: Your name is ﾅ「kasz, as you mentioned earlier.\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi, my name is ﾅ「kasz\\nAI: Hello ﾅ「kasz, it\\'s nice to meet you! My name is AI. How can I assist you today?\\nHuman: What is the best joke ever?\\nAI: That\\'s a subjective question, as humor is different for everyone. However, one of the most popular jokes of all time is \"Why did the chicken cross the road? To get to the other side!\"\\nHuman: What is my name?\\nAI: Your name is ﾅ「kasz, as you mentioned earlier.'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from langchain.memory import ConversationBufferWindowMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)               \n",
    "\n",
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Lukasz, it's nice to meet you. My name is AI. How can I assist you today?\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "conversation.predict(input=\"Hi, my name is Lukasz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer to 1+1 is 2.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "conversation.predict(input=\"What is 1+1?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't have access to that information. Could you please tell me your name?\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "conversation.predict(input=\"What is my name?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ConversationTokenBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "\n",
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})\n",
    "\n",
    "memory.load_memory_variables({})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI engage in small talk before discussing the day's schedule. The AI informs the human of a morning meeting with the product team, time to work on the LangChain project, and a lunch meeting with a customer interested in the latest AI developments.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human and AI engage in small talk before discussing the day's schedule. The AI informs the human of a morning meeting with the product team, time to work on the LangChain project, and a lunch meeting with a customer interested in the latest AI developments. The human asks what would be a good demo to show.\\nAI: Based on the customer's interest in AI developments, I would suggest showcasing our latest natural language processing capabilities. We could demonstrate how our AI can understand and respond to complex language queries, and even provide personalized recommendations based on the user's preferences. Additionally, we could highlight our machine learning algorithms and how they continuously improve the accuracy and efficiency of our AI. Would you like me to prepare a demo for the meeting?\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "\n",
    "\n",
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})\n",
    "\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"What would be a good demo to show?\")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
